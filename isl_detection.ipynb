{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d110133-3256-4852-8ddb-413d47065690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL (FIXED PATH)\n",
    "# =========================\n",
    "BASE_DIR = os.getcwd()\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"model.h5\")\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"model.h5 not found in {BASE_DIR}\")\n",
    "\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "print(\"✅ Model loaded successfully\")\n",
    "\n",
    "# =========================\n",
    "# MEDIAPIPE SETUP\n",
    "# =========================\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# =========================\n",
    "# LABELS\n",
    "# =========================\n",
    "alphabet = ['1','2','3','4','5','6','7','8','9']\n",
    "alphabet += list(string.ascii_uppercase)\n",
    "\n",
    "# =========================\n",
    "# FUNCTIONS\n",
    "# =========================\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_point = []\n",
    "\n",
    "    for landmark in landmarks.landmark:\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    base_x, base_y = temp_landmark_list[0][0], temp_landmark_list[0][1]\n",
    "    for i in range(len(temp_landmark_list)):\n",
    "        temp_landmark_list[i][0] -= base_x\n",
    "        temp_landmark_list[i][1] -= base_y\n",
    "\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "    if max_value == 0:\n",
    "        return temp_landmark_list\n",
    "\n",
    "    temp_landmark_list = [x / max_value for x in temp_landmark_list]\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "# =========================\n",
    "# WEBCAM INPUT\n",
    "# =========================\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "                landmark_list = calc_landmark_list(image, hand_landmarks)\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "\n",
    "                # Draw landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "\n",
    "                # Prepare dataframe\n",
    "                df = pd.DataFrame([pre_processed_landmark_list])\n",
    "\n",
    "                # Prediction\n",
    "                predictions = model.predict(df, verbose=0)\n",
    "                predicted_class = np.argmax(predictions)\n",
    "                confidence = np.max(predictions)\n",
    "\n",
    "                label = alphabet[predicted_class]\n",
    "\n",
    "                # Display result\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    f\"{label} ({confidence:.2f})\",\n",
    "                    (30, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.5,\n",
    "                    (0, 0, 255),\n",
    "                    3\n",
    "                )\n",
    "\n",
    "        cv2.imshow(\"Indian Sign Language Detector\", image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:  # ESC key\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a12daa-a1f7-44f3-8eba-d2a3180dd9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
